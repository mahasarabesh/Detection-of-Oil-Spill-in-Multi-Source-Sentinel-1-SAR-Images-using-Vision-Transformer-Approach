{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-03T10:24:38.491880Z",
     "iopub.status.busy": "2025-03-03T10:24:38.491515Z",
     "iopub.status.idle": "2025-03-03T10:24:45.892398Z",
     "shell.execute_reply": "2025-03-03T10:24:45.891640Z",
     "shell.execute_reply.started": "2025-03-03T10:24:38.491849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Collecting affine (from rasterio)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.3.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.12.14)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
      "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\n",
      "Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mmm\n",
      "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: affine, rasterio\n",
      "Successfully installed affine-2.4.0 rasterio-1.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio tqdm\n",
    "import os\n",
    "import rasterio\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, Normalize, Resize\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "class TifImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_names = [f for f in os.listdir(image_dir) if f.endswith(\".tif\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    # Load the image using rasterio\n",
    "      img_name = self.image_names[idx]\n",
    "      img_path = os.path.join(self.image_dir, img_name)\n",
    "      with rasterio.open(img_path) as src:\n",
    "          image = src.read()  # Read all bands\n",
    "\n",
    "      # Convert image to PyTorch tensor\n",
    "      image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "      # Fix NaN values\n",
    "      for band in range(image.shape[0]):  # Iterate over bands\n",
    "          band_data = image[band, :, :]\n",
    "          nan_mask = torch.isnan(band_data)\n",
    "          if nan_mask.any():\n",
    "              mean_value = band_data[~nan_mask].mean()  # Mean of non-NaN values\n",
    "              band_data[nan_mask] = mean_value  # Replace NaN with the mean\n",
    "\n",
    "      # Ensure 3-channel image for consistency\n",
    "      if image.shape[0] == 3:\n",
    "          pass\n",
    "      elif image.shape[0] > 3:\n",
    "          image = image[:3, :, :]\n",
    "      else:\n",
    "          image = image.expand(3, image.shape[1], image.shape[2])\n",
    "\n",
    "      # Load the corresponding mask\n",
    "      mask_name = img_name.replace(\".tif\", \"_mask.tif\")\n",
    "      mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "      with rasterio.open(mask_path) as src:\n",
    "          mask = src.read(1)  # Read single channel for binary mask\n",
    "\n",
    "      # Calculate the number of zeros and non-zeros in the mask\n",
    "      total_pixels = mask.size  # Total number of pixels in the mask\n",
    "      non_zero_pixels = (mask > 0).sum()  # Count of non-zero pixels\n",
    "      non_zero_percentage = (non_zero_pixels / total_pixels) * 100\n",
    "\n",
    "      # Determine label based on non-zero percentage\n",
    "      label = torch.tensor(1 if non_zero_percentage > 30 else 0, dtype=torch.long)\n",
    "\n",
    "      # Apply transforms if provided\n",
    "      if self.transform:\n",
    "          image = self.transform(image)\n",
    "\n",
    "      return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T10:24:45.894010Z",
     "iopub.status.busy": "2025-03-03T10:24:45.893444Z",
     "iopub.status.idle": "2025-03-03T10:24:46.179520Z",
     "shell.execute_reply": "2025-03-03T10:24:46.178593Z",
     "shell.execute_reply.started": "2025-03-03T10:24:45.893983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape after processing: torch.Size([3, 224, 224]), Label: 1\n",
      "Image shape after processing: torch.Size([3, 224, 224]), Label: 1\n",
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Compose, Normalize, Resize, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, ColorJitter,GaussianBlur\n",
    "\n",
    "# Define transformations with augmentations\n",
    "input_size = 224  # Required input size for ViT\n",
    "transform = Compose([\n",
    "    Resize((input_size, input_size)),            # Resize to ViT-compatible dimensions\n",
    "    #RandomHorizontalFlip(p=0.5),                # Randomly flip images horizontally\n",
    "    #RandomVerticalFlip(p=0.5),                  # Randomly flip images vertically\n",
    "    #RandomRotation(degrees=15),                 # Randomly rotate images within ±15 degrees\n",
    "    #GaussianBlur(kernel_size=(3, 3)),\n",
    "    #ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))     # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Initialize dataset\n",
    "image_dir = \"/kaggle/input/sar-ds-r-filtered-bal/sar_ds_r_filtered_bal/image_patches\"\n",
    "mask_dir = \"/kaggle/input/sar-ds-r-filtered-bal/sar_ds_r_filtered_bal/mask_patches\"\n",
    "dataset = TifImageDataset(image_dir=image_dir, mask_dir=mask_dir, transform=transform)\n",
    "\n",
    "# Example to check output\n",
    "for image, label in dataset:\n",
    "    print(f\"Image shape after processing: {image.shape}, Label: {label}\")\n",
    "    break\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for image, label in dataset:\n",
    "    print(f\"Image shape after processing: {image.shape}, Label: {label}\")\n",
    "    break\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T18:08:25.827852Z",
     "iopub.status.busy": "2025-03-02T18:08:25.827561Z",
     "iopub.status.idle": "2025-03-02T18:32:45.395005Z",
     "shell.execute_reply": "2025-03-02T18:32:45.394124Z",
     "shell.execute_reply.started": "2025-03-02T18:08:25.827831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs...\n",
      "Class distribution: {1: 3496, 0: 3496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 219/219 [01:36<00:00,  2.26it/s, Batch Loss=0.7088, Batch Accuracy=25.00%, Epoch Loss=0.6969, Epoch Accuracy=50.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] - Loss: 0.6969, Accuracy: 50.80%, Precision: 0.51, Recall: 0.51, F1 Score: 0.45, MAE: 0.49\n",
      "Best model updated with accuracy: 50.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6961, Batch Accuracy=50.00%, Epoch Loss=0.6954, Epoch Accuracy=53.65%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15] - Loss: 0.6954, Accuracy: 53.65%, Precision: 0.56, Recall: 0.54, F1 Score: 0.49, MAE: 0.46\n",
      "Best model updated with accuracy: 53.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6945, Batch Accuracy=56.25%, Epoch Loss=0.6939, Epoch Accuracy=54.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15] - Loss: 0.6939, Accuracy: 54.73%, Precision: 0.56, Recall: 0.55, F1 Score: 0.51, MAE: 0.45\n",
      "Best model updated with accuracy: 54.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 219/219 [01:37<00:00,  2.25it/s, Batch Loss=0.6889, Batch Accuracy=62.50%, Epoch Loss=0.6924, Epoch Accuracy=58.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15] - Loss: 0.6924, Accuracy: 58.32%, Precision: 0.60, Recall: 0.58, F1 Score: 0.56, MAE: 0.42\n",
      "Best model updated with accuracy: 58.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6912, Batch Accuracy=68.75%, Epoch Loss=0.6912, Epoch Accuracy=59.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15] - Loss: 0.6912, Accuracy: 59.61%, Precision: 0.61, Recall: 0.60, F1 Score: 0.58, MAE: 0.40\n",
      "Best model updated with accuracy: 59.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 219/219 [01:37<00:00,  2.25it/s, Batch Loss=0.6842, Batch Accuracy=81.25%, Epoch Loss=0.6893, Epoch Accuracy=63.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15] - Loss: 0.6893, Accuracy: 63.36%, Precision: 0.64, Recall: 0.63, F1 Score: 0.63, MAE: 0.37\n",
      "Best model updated with accuracy: 63.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 219/219 [01:36<00:00,  2.26it/s, Batch Loss=0.6887, Batch Accuracy=62.50%, Epoch Loss=0.6879, Epoch Accuracy=65.05%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15] - Loss: 0.6879, Accuracy: 65.05%, Precision: 0.66, Recall: 0.65, F1 Score: 0.65, MAE: 0.35\n",
      "Best model updated with accuracy: 65.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6840, Batch Accuracy=62.50%, Epoch Loss=0.6865, Epoch Accuracy=66.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15] - Loss: 0.6865, Accuracy: 66.16%, Precision: 0.66, Recall: 0.66, F1 Score: 0.66, MAE: 0.34\n",
      "Best model updated with accuracy: 66.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6898, Batch Accuracy=68.75%, Epoch Loss=0.6852, Epoch Accuracy=68.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15] - Loss: 0.6852, Accuracy: 68.52%, Precision: 0.69, Recall: 0.69, F1 Score: 0.69, MAE: 0.31\n",
      "Best model updated with accuracy: 68.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 219/219 [01:35<00:00,  2.29it/s, Batch Loss=0.6840, Batch Accuracy=68.75%, Epoch Loss=0.6835, Epoch Accuracy=70.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15] - Loss: 0.6835, Accuracy: 70.34%, Precision: 0.70, Recall: 0.70, F1 Score: 0.70, MAE: 0.30\n",
      "Best model updated with accuracy: 70.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6817, Batch Accuracy=75.00%, Epoch Loss=0.6816, Epoch Accuracy=70.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15] - Loss: 0.6816, Accuracy: 70.97%, Precision: 0.71, Recall: 0.71, F1 Score: 0.71, MAE: 0.29\n",
      "Best model updated with accuracy: 70.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 219/219 [01:37<00:00,  2.25it/s, Batch Loss=0.6898, Batch Accuracy=68.75%, Epoch Loss=0.6802, Epoch Accuracy=73.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15] - Loss: 0.6802, Accuracy: 73.00%, Precision: 0.74, Recall: 0.73, F1 Score: 0.73, MAE: 0.27\n",
      "Best model updated with accuracy: 73.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6808, Batch Accuracy=75.00%, Epoch Loss=0.6783, Epoch Accuracy=73.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15] - Loss: 0.6783, Accuracy: 73.76%, Precision: 0.75, Recall: 0.74, F1 Score: 0.73, MAE: 0.26\n",
      "Best model updated with accuracy: 73.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 219/219 [01:36<00:00,  2.27it/s, Batch Loss=0.6820, Batch Accuracy=75.00%, Epoch Loss=0.6766, Epoch Accuracy=73.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15] - Loss: 0.6766, Accuracy: 73.63%, Precision: 0.75, Recall: 0.74, F1 Score: 0.73, MAE: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 219/219 [01:37<00:00,  2.25it/s, Batch Loss=0.6736, Batch Accuracy=93.75%, Epoch Loss=0.6749, Epoch Accuracy=74.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15] - Loss: 0.6749, Accuracy: 74.46%, Precision: 0.77, Recall: 0.74, F1 Score: 0.74, MAE: 0.26\n",
      "Best model updated with accuracy: 74.46%\n",
      "Training complete. Checkpoints and metrics saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from timm import create_model\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_classes = 2  # Binary classification\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.fc.in_features, num_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Enable DataParallel for multi-GPU support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs...\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Check class distribution\n",
    "class_counts = Counter(label.item() for _, label in dataset)\n",
    "print(f\"Class distribution: {class_counts}\")\n",
    "\n",
    "class_weights = torch.tensor([1.0, len(dataset) / class_counts[1]], device=device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "metrics_history = []\n",
    "checkpoint_dir = \"\"\n",
    "#os.makedirs(checkpoint_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "metrics_csv_path = os.path.join(checkpoint_dir, \"metrics_history_bal_40_L.csv\")\n",
    "\n",
    "best_accuracy = 0.0  # To track the best model\n",
    "\n",
    "# Training loop with checkpoint saving\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Initialize progress bar for the current epoch\n",
    "    progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    for batch_idx, (images, labels) in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Calculate batch metrics\n",
    "        batch_loss = loss.item()\n",
    "        batch_accuracy = 100 * (predicted == labels).sum().item() / labels.size(0)\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            \"Batch Loss\": f\"{batch_loss:.4f}\",\n",
    "            \"Batch Accuracy\": f\"{batch_accuracy:.2f}%\",\n",
    "            \"Epoch Loss\": f\"{running_loss / (batch_idx + 1):.4f}\",\n",
    "            \"Epoch Accuracy\": f\"{100 * correct / total:.2f}%\"\n",
    "        })\n",
    "\n",
    "    # Compute additional metrics\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    epoch_precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    epoch_recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    epoch_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    epoch_mae = mean_absolute_error(all_labels, all_predictions)\n",
    "\n",
    "    # Save metrics\n",
    "    metrics_history.append({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"loss\": epoch_loss,\n",
    "        \"accuracy\": epoch_accuracy,\n",
    "        \"precision\": epoch_precision,\n",
    "        \"recall\": epoch_recall,\n",
    "        \"f1_score\": epoch_f1,\n",
    "        \"mae\": epoch_mae\n",
    "    })\n",
    "\n",
    "    # Write metrics to CSV\n",
    "    metrics_df = pd.DataFrame(metrics_history)\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Precision: {epoch_precision:.2f}, Recall: {epoch_recall:.2f}, F1 Score: {epoch_f1:.2f}, MAE: {epoch_mae:.2f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if epoch_accuracy > best_accuracy:\n",
    "        best_accuracy = epoch_accuracy\n",
    "        best_model_path = os.path.join(checkpoint_dir, \"best_model_bal_40_L.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_accuracy,\n",
    "        }, best_model_path)\n",
    "        print(f\"Best model updated with accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete. Checkpoints and metrics saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T10:25:07.991011Z",
     "iopub.status.busy": "2025-03-03T10:25:07.990565Z",
     "iopub.status.idle": "2025-03-03T10:25:16.042775Z",
     "shell.execute_reply": "2025-03-03T10:25:16.041896Z",
     "shell.execute_reply.started": "2025-03-03T10:25:07.990972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:05<00:00, 20.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Step 1: Define Model and Load Weights\n",
    "# Step 4: Load Pre-trained ViT Model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_classes = 2  # Binary classification\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.fc.in_features, num_classes),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Enable DataParallel for multi-GPU support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs...\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "from collections import OrderedDict \n",
    "#models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "checkpoint_path = \"/kaggle/working/best_model_bal_40_L.pth\"  # Replace with the desired epoch checkpoint file\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=True)\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# Remove 'module.' prefix from state dict keys if present\n",
    "new_state_dict = OrderedDict()\n",
    "for key, value in state_dict.items():\n",
    "    new_key = key.replace(\"module.\", \"\")\n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "# Load the modified state dict into the model\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T10:26:20.155440Z",
     "iopub.status.busy": "2025-03-03T10:26:20.155094Z",
     "iopub.status.idle": "2025-03-03T10:30:39.630906Z",
     "shell.execute_reply": "2025-03-03T10:30:39.630021Z",
     "shell.execute_reply.started": "2025-03-03T10:26:20.155417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2273 1223]\n",
      " [ 362 3134]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no oil spill       0.86      0.65      0.74      3496\n",
      "   oil spill       0.72      0.90      0.80      3496\n",
      "\n",
      "    accuracy                           0.77      6992\n",
      "   macro avg       0.79      0.77      0.77      6992\n",
      "weighted avg       0.79      0.77      0.77      6992\n",
      "\n",
      "Precision: 0.72\n",
      "Recall (Sensitivity, TPR): 0.90\n",
      "F1 Score: 0.80\n",
      "Cohen's Kappa: 0.55\n",
      "True Positive Rate (TPR): 0.90\n",
      "True Negative Rate (TNR): 0.65\n",
      "False Positive Rate (FPR): 0.35\n",
      "False Negative Rate (FNR): 0.10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: Evaluate and Collect Predictions\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)  # Get predicted class\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Step 3: Generate Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "class_names = ['no oil spill', 'oil spill']  # Replace with your class names if needed\n",
    "\n",
    "# Extract True Positives (TP), False Positives (FP), True Negatives (TN), False Negatives (FN)\n",
    "TP = cm[1, 1]\n",
    "FP = cm[0, 1]\n",
    "TN = cm[0, 0]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Metrics Calculations\n",
    "precision = precision_score(all_labels, all_preds, average='binary')\n",
    "recall = recall_score(all_labels, all_preds, average='binary')\n",
    "f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # True Positive Rate (Sensitivity)\n",
    "TNR = TN / (TN + FP) if (TN + FP) > 0 else 0  # True Negative Rate (Specificity)\n",
    "FPR = FP / (FP + TN) if (FP + TN) > 0 else 0  # False Positive Rate\n",
    "FNR = FN / (FN + TP) if (FN + TP) > 0 else 0  # False Negative Rate\n",
    "\n",
    "# Display Metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall (Sensitivity, TPR): {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "print(f\"True Positive Rate (TPR): {TPR:.2f}\")\n",
    "print(f\"True Negative Rate (TNR): {TNR:.2f}\")\n",
    "print(f\"False Positive Rate (FPR): {FPR:.2f}\")\n",
    "print(f\"False Negative Rate (FNR): {FNR:.2f}\")\n",
    "\n",
    "# Step 4: Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6538042,
     "sourceId": 10565750,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
